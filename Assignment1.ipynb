{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pantchayan/Deep-Learning-Assignment---IIT-J/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e85d83",
      "metadata": {
        "id": "84e85d83"
      },
      "source": [
        "### Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad36c77",
      "metadata": {
        "id": "fad36c77",
        "outputId": "1de650ac-5aef-4df5-bde4-ccb12f59b218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*************************  1  *************************\n",
            "The Initial weights are  0.2 0.72 0.22\n",
            "The optimal parameters @ Alpha-Learning rate  0.1 are :  [0.02652391 0.29285576 0.16127508]\n",
            "The Loss would be :  20.023674532921465\n",
            "*************************  2  *************************\n",
            "The Initial weights are  0.56 0.73 0.77\n",
            "The optimal parameters @ Alpha-Learning rate  0.01 are :  [0.07426695 0.29349547 0.33756788]\n",
            "The Loss would be :  20.071152444935272\n",
            "*************************  3  *************************\n",
            "The Initial weights are  0.5 0.59 0.01\n",
            "The optimal parameters @ Alpha-Learning rate  0.05 are :  [0.06630978 0.2819435  0.00983765]\n",
            "The Loss would be :  20.023960620727483\n",
            "*************************  4  *************************\n",
            "The Initial weights are  0.5 0.91 0.0\n",
            "The optimal parameters @ Alpha-Learning rate  0.5 are :  [0.22739817 0.44470325 0.        ]\n",
            "The Loss would be :  20.197282421551833\n",
            "*************************  5  *************************\n",
            "The Initial weights are  0.47 0.94 0.97\n",
            "The optimal parameters @ Alpha-Learning rate  0.25 are :  [0.06233119 0.30293021 0.37079918]\n",
            "The Loss would be :  20.084061190880643\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def loss_function(params, x1, x2, x3):\n",
        "    x1 = params[0]\n",
        "    x2 = params[1]\n",
        "    x3 = params[2]\n",
        "    return 2*x1**2 + 2.4*x2**4 + 1.1*x3**3 + 20\n",
        "\n",
        "def gradient(params, x1, x2, x3):\n",
        "    grad_x1 = 4*params[0]\n",
        "    grad_x2 = 9.6*params[1]**3\n",
        "    grad_x3 = 3.3*params[2]**2\n",
        "    return np.array([grad_x1, grad_x2, grad_x3])\n",
        "\n",
        "def optimize(learning_rate, num_iterations,e,x1, x2, x3):\n",
        "    params = np.array([x1, x2, x3])\n",
        "    ## Need to implement the error condition as mentioned by Himanshu Sir wiht Norm\n",
        "#     for i in range(num_iterations):\n",
        "#         params = params - learning_rate * gradient(params, x1, x2, x3)\n",
        "#     return params\n",
        "    ind = 0\n",
        "    er = 1\n",
        "    while ((ind < num_iterations) & (er > e) ):\n",
        "        \n",
        "        params_new = params - learning_rate * gradient(params, x1, x2, x3)\n",
        "        \n",
        "        er = norm(params_new)\n",
        "        params = params_new\n",
        "        ind+=1\n",
        "        \n",
        "    return params   \n",
        "\n",
        "lr = [0.1,0.01,0.05,0.5,0.25]\n",
        "for i in range(len(lr)):\n",
        "    x1 = round(np.random.random(),2)\n",
        "    x2 = round(np.random.random(),2)\n",
        "    x3 = round(np.random.random(),2)\n",
        "    optimal_params = optimize(0.005, 100,lr[i],x1, x2, x3)\n",
        "    #optimal_params = optimize(0.1, 100, 0, 0, 0)\n",
        "    print(\"*\"*25,_,i+1,_,\"*\"*25)\n",
        "    print(\"The Initial weights are \", x1,x2,x3)\n",
        "    print(\"The optimal parameters @ Alpha-Learning rate  {} are : \".format(lr[i]), optimal_params)\n",
        "    print(\"The Loss would be : \", loss_function(optimal_params,optimal_params[0],optimal_params[1],optimal_params[2] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a86caa",
      "metadata": {
        "id": "d6a86caa",
        "outputId": "f7495c2a-15fd-409a-b523-9f0a4c80333e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_quadratic(a, b, c):\n",
        "    # Generate x1 values from -10 to 10 with a step of 0.1\n",
        "    x1 = np.arange(-10, 10, 0.1)\n",
        "    \n",
        "    # Generate x2 values from -10 to 10 with a step of 0.1\n",
        "    x2 = np.arange(-10, 10, 0.1)\n",
        "    \n",
        "    # Generate x3 values from -10 to 10 with a step of 0.1\n",
        "    x3 = np.arange(-10, 10, 0.1)\n",
        "    \n",
        "    # Calculate y values using the equation\n",
        "    y = a * x1**2 + b * x2**4 + c * x3**3 + 20\n",
        "\n",
        "    # Plot the x and y values\n",
        "    plt.plot(y)\n",
        "\n",
        "    # Add labels and title to the plot\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.title('Quadratic Equation: y = ax1^2 + bx2^4 + cx3^3 + 20')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Plot the equation\n",
        "plot_quadratic(1, 1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fac2c3f",
      "metadata": {
        "id": "7fac2c3f"
      },
      "source": [
        "### Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8adc70f",
      "metadata": {
        "id": "f8adc70f"
      },
      "source": [
        "Universal Approximation Theorem : \n",
        "\n",
        "A feed forward neural network with single hidden layer and finite number of neurons can approximate continuous functions on compace subsets of R^N under mild assumptions on the activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96781107",
      "metadata": {
        "id": "96781107",
        "outputId": "dba08da4-3746-4952-d3c0-d80e552c4c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 267ms/step - loss: 2082.3850\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1996.0294\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1885.2878\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1721.7504\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1753.1989\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2156.5076\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1857.7340\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1825.1216\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1702.0035\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1688.7651\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1724.8525\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1765.3610\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1718.4994\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1629.2169\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1569.3363\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1761.7736\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1721.0356\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1557.6500\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1593.0072\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1659.7806\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1576.4639\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1476.9169\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1591.0100\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1622.4272\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1591.1531\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1583.4871\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1589.1943\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1584.1641\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1586.9250\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1511.9569\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1529.3417\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1516.3994\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1512.1428\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1444.4994\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1420.2043\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1427.4325\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1456.8153\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1452.1190\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1455.8125\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1478.6238\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1465.9800\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1462.8560\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1434.8793\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1381.3131\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1350.4810\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1335.7344\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1347.6589\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1311.3938\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1301.0503\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1350.1064\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1367.6776\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1426.2461\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1445.3203\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1383.9524\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1358.1653\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1338.7563\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1310.9275\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1231.4653\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1206.9396\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1133.0802\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1065.1606\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1048.3108\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1068.5306\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1149.4644\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1173.0787\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1150.0709\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1161.2881\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1191.0227\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1204.2091\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1163.0632\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1110.9755\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1019.8695\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1034.2535\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1026.3929\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1065.1171\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1076.5234\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1110.8547\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1154.0127\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1105.8727\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1081.8081\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1086.1183\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1091.7202\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1085.5698\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1056.0144\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1002.0380\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 965.3539\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 935.9780\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 900.7514\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 829.2698\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 784.3466\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 801.6699\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 833.2827\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 861.6239\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 820.6972\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 777.8983\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 758.7542\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 756.2441\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 809.2729\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 780.3431\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 761.2662\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 738.8972\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 736.9469\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 757.3209\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 704.6741\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 666.2742\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 682.0538\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 712.9631\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 705.1223\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 674.3157\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 672.9023\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 686.6249\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 683.6733\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 638.7261\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 626.7347\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 660.4137\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 665.9647\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 635.0276\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 666.4233\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 645.1706\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 607.4138\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 670.8939\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 654.8071\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 672.3908\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 711.8616\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 679.5312\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 601.5404\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 581.8387\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 648.3791\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 619.5911\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 685.4301\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 798.7525\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 728.8532\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 658.7182\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 586.1940\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 527.1667\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 526.5421\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 633.7170\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 743.5090\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 729.3753\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 717.5266\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 671.6951\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 590.1000\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 531.0563\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 568.7467\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 579.0200\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 606.2895\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 612.8699\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 650.8221\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 710.9394\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 779.3483\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 739.4648\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 665.5750\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 622.9800\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 603.8987\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 542.6302\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 497.5878\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 551.3904\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 612.6463\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 647.1458\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 716.1237\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 689.2870\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 664.2988\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 654.1112\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 618.0347\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 542.0023\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 494.1544\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 497.9241\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 499.2517\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 512.3539\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 539.3592\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 489.4337\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 524.2698\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 615.5114\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 546.8173\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 524.5720\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 631.1724\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 627.2737\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 590.8646\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 616.0544\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 527.3473\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 479.6970\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 533.4612\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 498.4900\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 461.3438\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 495.7622\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 522.7930\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 531.2198\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 563.0364\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 570.2905\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 540.4825\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 546.1055\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 519.4178\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 431.7308\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 438.6261\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 458.2986\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 402.6825\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 391.7553\n",
            "Epoch 198/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 4ms/step - loss: 458.6652\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 432.6105\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 437.8089\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 523.5660\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 539.9324\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 476.8160\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 502.7581\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 477.8973\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 471.0887\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 511.2802\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 544.3129\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 444.3746\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 507.6485\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 584.5867\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 475.8045\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 593.6860\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 705.9484\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 605.7933\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 688.8127\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 622.8271\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 441.9216\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 472.0385\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 583.3708\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 532.9051\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 586.4044\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 677.1361\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 626.3983\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 650.2465\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 770.4742\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 778.5520\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 788.6912\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 726.4455\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 627.0693\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 575.9635\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 581.1281\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 546.9578\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 540.4217\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 537.7266\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 527.0581\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 556.6472\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 530.0925\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 504.7517\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 545.5414\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 597.7079\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 612.9064\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 588.2809\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 580.4045\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 552.8932\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 545.0164\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 523.2332\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 522.2670\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 505.6550\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 527.7569\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 521.4286\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 484.7947\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 507.1448\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 584.5305\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 561.8720\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 539.5712\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 539.4813\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 503.5316\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 516.1622\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 544.7064\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 531.7339\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 543.9973\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 528.9438\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 491.2466\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 470.8955\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 483.8627\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 443.8488\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 425.6297\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 459.8932\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 419.3394\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 387.7247\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 432.9361\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 400.0271\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 380.7356\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 441.5903\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 430.4071\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 395.5718\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 493.9283\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 515.4457\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 430.5685\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 450.3185\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 468.9466\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 355.0498\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 333.3010\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 362.0265\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 307.4018\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 303.1786\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 349.9654\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 304.6912\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 299.2882\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 350.1982\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 325.8264\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 319.8120\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 367.7181\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 329.1988\n",
            "Epoch 296/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 8ms/step - loss: 341.7815\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 391.2973\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 337.1566\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 312.2227\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 355.9858\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 319.9786\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 311.9277\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 354.5322\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 300.6667\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 288.0876\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 324.4366\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 275.4610\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 271.7754\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 312.3623\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 270.7893\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 269.1674\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 305.8770\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 273.4044\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 270.2092\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 309.0436\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 274.5014\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 270.2922\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 304.3485\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 277.8620\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 271.5169\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 309.2432\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 278.6658\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 270.8930\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 304.4598\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 280.3667\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 270.3068\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 307.4660\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 279.2350\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 268.9578\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 302.4211\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 279.7590\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 267.6034\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 306.5336\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 278.0266\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 265.9763\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 300.4241\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 278.4861\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 264.1650\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 305.8034\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 275.3423\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 261.4139\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 298.8802\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 275.7560\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 260.0818\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 305.8672\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 270.2698\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 255.4983\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 297.5145\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 267.7875\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 254.0501\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 305.9779\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 258.8780\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 247.9103\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 300.5339\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 251.7138\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 248.2898\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 317.9924\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 243.1984\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 244.8074\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 322.3452\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 230.3043\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 247.8779\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 357.0638\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 222.3010\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 250.4953\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 375.7422\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 209.8913\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 250.1677\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 401.1724\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 206.1802\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 241.0512\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 373.1074\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 207.5788\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 253.2429\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 403.7513\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 224.2760\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 276.5396\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 423.1913\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 247.1786\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 325.8461\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 482.3705\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 278.9050\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 370.2723\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 476.1155\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 285.7105\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 314.4665\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 326.9268\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 264.0331\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 266.2527\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 262.8728\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 225.3055\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 237.0908\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 257.0100\n",
            "Epoch 394/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 3ms/step - loss: 211.7930\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 216.7600\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 232.5358\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 213.0379\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 215.7772\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 234.1097\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 212.0842\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 217.7594\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 225.1108\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 213.8311\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 215.9472\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 224.4722\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 211.5961\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 217.4105\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 217.9867\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 212.5640\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 214.9248\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 217.5148\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 210.4742\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 216.4949\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 212.7903\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 211.3840\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 213.1843\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 212.9529\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 209.6430\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 214.6635\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 209.9019\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 211.4152\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 211.4921\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 210.7711\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 209.1524\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 212.2109\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 207.7330\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 210.4500\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 208.7480\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 208.8926\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 208.2443\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 209.6691\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 206.7738\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 209.3872\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 206.6665\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 207.4561\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 206.3387\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 206.3712\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 204.5103\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 205.5897\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 203.0470\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 203.9783\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 202.5377\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 202.9938\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 202.0284\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 203.0896\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 201.6579\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 202.9785\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 201.6899\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 202.4385\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 201.5660\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 202.0861\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 201.0081\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 201.7770\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 200.4693\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 201.1128\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 200.0605\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 200.3649\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 199.4603\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 199.7768\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 198.6959\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 199.0989\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 198.0027\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 198.2201\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 197.3124\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 197.3515\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 196.4769\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 196.5235\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 195.5792\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 195.5738\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 194.7043\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 194.5021\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 193.7695\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 193.4046\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 192.7133\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 192.2370\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 191.5792\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 190.9024\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 190.3727\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 189.4065\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 189.0395\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 187.8169\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 187.6077\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 186.2879\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 186.2688\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 185.1736\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 185.2331\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 184.4677\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 184.5565\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 183.7160\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 184.0424\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 182.8990\n",
            "Epoch 492/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 3ms/step - loss: 183.3452\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 182.1810\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 182.4917\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 181.4754\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 181.6926\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 180.6823\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 180.9881\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 179.8454\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 180.2627\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 179.0041\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 179.4438\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 178.0911\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 178.5526\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 177.0450\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 177.6226\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 175.9580\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 176.7019\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 175.0936\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 175.9072\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 174.6107\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 175.3394\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 174.1980\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 174.9770\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 173.6086\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 174.5940\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 172.9637\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 174.0054\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 172.3498\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 173.2756\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 996us/step - loss: 171.6694\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 172.5460\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 170.8431\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 171.8344\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 169.9276\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 171.0560\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 168.9971\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 170.1643\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 168.0273\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 169.1932\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 166.9501\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 168.1850\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 165.7807\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 167.1585\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 164.6769\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 166.1732\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 163.8839\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 165.3444\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 163.4171\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 164.7309\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 162.9179\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 164.2625\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 162.2334\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 163.7359\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 161.5038\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 163.0204\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 160.8185\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 162.1713\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 160.1105\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 161.3160\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 159.2956\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 160.5078\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 158.3999\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 159.7083\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 157.5153\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 158.8804\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 156.6901\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 158.0596\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 155.9056\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 157.3204\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 155.1336\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 156.6863\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 154.3793\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 156.0910\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 153.6606\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 155.4429\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 152.9683\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 154.7172\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 152.2622\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 153.9588\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 151.5094\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 153.2147\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 150.7203\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 152.4933\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 149.9443\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 151.7831\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 149.2446\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 151.0982\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 148.6872\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 150.4942\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 148.3167\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 150.0271\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 148.0723\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 149.7009\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 147.8006\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 149.4567\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 147.4309\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 149.1975\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 147.0156\n",
            "Epoch 590/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 148.8479\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 146.6205\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 148.4060\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 146.2488\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 147.9304\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 145.8527\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 147.4824\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 145.3954\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 147.0762\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 144.8915\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 146.6763\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 144.3867\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 146.2380\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 143.9128\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 145.7502\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 143.4607\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 145.2405\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 142.9955\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 144.7444\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 142.4922\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 144.2735\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 141.9586\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 143.8091\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 141.4247\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 143.3230\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 140.9147\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 142.8051\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 140.4288\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 142.2709\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 139.9476\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 141.7475\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 139.4529\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 141.2510\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 138.9452\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 140.7769\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 138.4418\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 140.3080\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 137.9614\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 139.8315\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 137.5081\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 139.3497\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 137.0696\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 138.8771\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 136.6274\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 138.4259\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 136.1714\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 137.9957\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 135.7061\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 137.5733\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 135.2439\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 137.1426\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 134.7942\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 136.6967\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 134.3554\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 136.2412\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 133.9169\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 135.7886\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 133.4673\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 135.3479\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 133.0035\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 134.9174\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 132.5321\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 134.4865\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 132.0638\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 134.0443\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 131.6054\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 133.5871\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 131.1550\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 133.1211\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 130.7037\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 132.6568\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 130.2431\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 132.2016\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 129.7706\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 131.7542\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 129.2916\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 131.3061\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 128.8156\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 130.8477\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 128.3489\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 130.3755\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 127.8920\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 129.8943\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 127.4390\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 129.4144\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 126.9826\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 128.9450\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 126.5197\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 128.4888\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 126.0539\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 128.0414\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 125.5935\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 127.5944\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 125.1464\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 127.1428\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 124.7154\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 126.6880\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 124.2966\n",
            "Epoch 688/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 3ms/step - loss: 126.2377\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 123.8821\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 125.8012\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 123.4639\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 125.3834\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 123.0396\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 997us/step - loss: 124.9817\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 122.6127\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 124.5868\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 122.1901\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 124.1875\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 121.7786\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 123.7776\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 121.3799\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 123.3590\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 120.9897\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 122.9405\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 120.5999\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 122.5326\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 120.2031\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 122.1416\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 119.7971\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 121.7660\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 119.3863\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 121.3967\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 118.9799\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 121.0219\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 118.5872\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 120.6339\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 118.2131\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 120.2338\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 117.8554\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 119.8310\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 117.5057\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 119.4395\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 117.1532\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 119.0706\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 116.7904\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 118.7273\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 116.4172\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 118.4017\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 116.0415\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 118.0789\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 115.6760\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 117.7432\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 115.3320\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 117.3869\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 115.0143\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 117.0141\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 114.7172\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 996us/step - loss: 116.6399\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 114.4258\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 116.2840\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 114.1218\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 115.9617\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 113.7918\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 115.6765\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 113.4340\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 115.4159\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 113.0603\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 115.1549\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 112.6914\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 114.8659\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 112.3501\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 114.5319\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 112.0511\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 114.1556\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 111.7923\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 113.7598\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 111.5519\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 113.3793\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 111.2946\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 113.0483\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 110.9875\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 112.7869\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 110.6155\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 112.5888\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 110.1894\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 112.4174\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 109.7432\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 112.2144\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 109.3250\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 111.9250\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 108.9829\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 111.5260\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 108.7467\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 111.0389\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 108.6062\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 110.5225\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 108.5008\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 110.0529\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 108.3380\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 109.7053\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 108.0364\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 109.5323\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 107.5662\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 109.5327\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 106.9586\n",
            "Epoch 786/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 109.6203\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 106.2876\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 109.6313\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 105.6567\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 109.3972\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 105.1969\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 108.8449\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 105.0409\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 108.0383\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 105.2412\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 107.1247\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 105.6687\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 106.2569\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 106.0061\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 105.5903\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 105.9181\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 105.3367\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 105.2818\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 105.7300\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 104.2266\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 106.7980\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 102.9292\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 108.0815\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 101.4499\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 108.6952\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 99.8930\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 107.9613\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 98.7450\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 106.0713\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 98.9155\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 103.9086\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 101.1742\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 102.1057\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 105.0251\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 100.3272\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 107.9988\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 97.8931\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 107.5398\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 95.4210\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 104.1602\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 95.4009\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 100.9588\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 101.0865\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 100.1790\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 113.0648\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 99.8428\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 123.1405\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 95.1326\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 120.1297\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 86.0479\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 108.0725\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 77.8407\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 100.0240\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 78.5310\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 115.8130\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 119.8319\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 259.5265\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 225.1026\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 476.7881\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 141.9004\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 151.0788\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 160.9129\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 304.4106\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 125.8999\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 138.2373\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 84.3228\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 101.2543\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 90.9699\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 163.6558\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 125.4124\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 228.4589\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 99.4133\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 129.8368\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 120.8301\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 246.8628\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 129.8668\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 188.2400\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 94.5472\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 104.6365\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.2108\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 149.0800\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 125.0767\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 241.6473\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 90.6745\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 100.8008\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 81.6071\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 145.9605\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 130.4011\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 258.0683\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 101.0213\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 109.1596\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 69.5998\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 82.5145\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 72.1546\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 126.2623\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 116.9077\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 232.9845\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 91.3987\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 105.8349\n",
            "Epoch 885/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 6ms/step - loss: 74.9284\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 117.1613\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 115.1552\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 237.0373\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 107.7061\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 139.6371\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 76.7222\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 86.6604\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 62.8427\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.4910\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 88.0491\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 179.7518\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 107.9972\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 177.4252\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 79.8468\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 93.5123\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 76.8855\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 140.3048\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 124.4869\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 243.5723\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 95.7819\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 102.8723\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.5957\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 68.8772\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 51.3151\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 59.3998\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 52.7803\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 73.5334\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 96.4140\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 147.0990\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 236.4113\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 195.8640\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 230.7262\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 239.1559\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 187.7561\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 218.7773\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 167.2709\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 165.8466\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 167.7062\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 138.2453\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 142.3507\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 123.6406\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 118.7961\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 120.7341\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 107.5263\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 117.0222\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 100.4412\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 107.7943\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 96.1812\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 99.2174\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 95.2667\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 93.9294\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 95.6793\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 90.7952\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 95.0133\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 89.0709\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 93.2284\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 89.2505\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 91.7479\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 91.5870\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 91.1891\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 94.6999\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 90.8363\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 96.1552\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 89.9264\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 94.8750\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 88.7135\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 91.9668\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 87.9762\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 89.0200\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 88.0145\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 86.7795\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 88.3831\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.2707\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 88.4187\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 84.4284\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 87.8914\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 84.4053\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 87.0993\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 85.3700\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 86.4093\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 87.0676\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 85.8250\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 88.6312\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.0451\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 89.0481\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.9163\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 87.9742\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 82.7293\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.9555\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 82.0308\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.8508\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 82.1953\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 82.2081\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.1254\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 81.0941\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 84.2521\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 80.3145\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 84.8825\n",
            "Epoch 984/1000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step - loss: 79.7734\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 84.6959\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 79.6940\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.9428\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 80.5213\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 83.1383\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 82.5280\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 82.5357\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 85.2946\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 81.8319\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 87.5203\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 80.4392\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 87.7765\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 78.1614\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 85.7578\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 75.5308\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 82.4832\n",
            "4/4 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Generate input data\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = x**2\n",
        "#y = np.sin(x)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(150, input_shape=(1,), activation='tanh'),\n",
        "    \n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x, y, epochs=1000, batch_size=100)\n",
        "\n",
        "# Predict values using the trained model\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Plot the predicted values\n",
        "plt.plot(x, predictions, label='Predicted')\n",
        "\n",
        "# Plot the true values\n",
        "plt.plot(x, y, label='True')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d50c82",
      "metadata": {
        "id": "c9d50c82"
      },
      "source": [
        "### Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82beca7e",
      "metadata": {
        "id": "82beca7e",
        "outputId": "8a8679b6-447b-4ef2-d28a-218683857875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.49786619 0.55721467 0.52009003 0.55599675]\n",
            " [0.67746473 0.00450966 0.49591706 0.84808355]\n",
            " [0.33451924 0.37359891 0.50877762 0.14713408]\n",
            " [0.65774433 0.08829666 0.51658233 0.7526052 ]]\n",
            "Output after training: \n",
            " [[0.32730632]\n",
            " [0.32481328]\n",
            " [0.32514831]\n",
            " [0.32686596]]\n",
            "Mean Squared Error: \n",
            " 0.006943489914680642\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "class ConvolutionalNeuralNetwork:\n",
        "    def __init__(self, x, y, learning_rate=0.1, epochs=100):\n",
        "        self.input = x\n",
        "        \n",
        "        self.weights1 = np.random.rand(2,2,1,1)  # initialize weights\n",
        "        \n",
        "       \n",
        "        \n",
        "        self.bias = np.random.rand(2, 1)\n",
        "        self.y = y\n",
        "        self.output = np.zeros(self.y.shape)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def feedforward(self):\n",
        "        #self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        conv_layer = tf.nn.conv2d(self.input, self.weights1, strides=(1, 1), padding=\"SAME\")\n",
        "        \n",
        "        max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='SAME')\n",
        "        self.layer1 = max_pool_2d(self.input)\n",
        "        self.output = sigmoid(self.layer1)\n",
        "\n",
        "    def backprop(self):\n",
        "        \n",
        "        \n",
        "        d_weights1 = (2 * (self.y - self.output) * sigmoid_derivative(self.output))\n",
        "        \n",
        "        d_weights1 = d_weights1.reshape(2, 2, 1, 1)\n",
        "        \n",
        "        self.weights1 += d_weights1 * self.learning_rate\n",
        "        \n",
        "\n",
        "    def train(self):\n",
        "        for i in range(self.epochs):\n",
        "            self.feedforward()\n",
        "            self.backprop()\n",
        "\n",
        "    def mean_squared_error(self):\n",
        "        return np.mean(np.square(self.y - self.output))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X = np.array([[0.1, 0.5, 0.6, 0.3], [0.2, 0.4, 0.2,0.6], [0.4, 0.3, 0.4,0.4], [0.5, 0.2, 0.5,0.3]])\n",
        "    X = X.reshape(1, 4, 4, 1)\n",
        "    y = np.array([[0.2], [0.3], [0.4], [0.4]])\n",
        "    y = y.reshape(1, 2, 2, 1)\n",
        "    cnn = ConvolutionalNeuralNetwork(X, y)\n",
        "    cnn.train()\n",
        "    print(\"Output after training: \\n\", cnn.output)\n",
        "    print(\"Mean Squared Error: \\n\", cnn.mean_squared_error())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba1e958",
      "metadata": {
        "id": "1ba1e958"
      },
      "outputs": [],
      "source": [
        "## Version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03f02b0",
      "metadata": {
        "id": "b03f02b0"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# def sigmoid(x):\n",
        "#     return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# def sigmoid_derivative(x):\n",
        "#     return x * (1 - x)\n",
        "\n",
        "# class ConvolutionalNeuralNetwork:\n",
        "#     def __init__(self, x, y, learning_rate=0.1, epochs=100):\n",
        "#         self.input = x\n",
        "#         print(self.input.shape)\n",
        "#         print(self.input)\n",
        "#         self.weights1 = np.random.rand(2,2)  # initialize weights\n",
        "#         print(self.weights1.reshape(1,2,2,1))\n",
        "       \n",
        "#         print(self.weights1.shape)\n",
        "#         #self.weights2 = np.random.rand(2, 1)\n",
        "#         self.bias = np.random.rand(2, 1)\n",
        "#         self.y = y\n",
        "#         self.output = np.zeros(self.y.shape)\n",
        "#         self.learning_rate = learning_rate\n",
        "#         self.epochs = epochs\n",
        "\n",
        "#     def feedforward(self):\n",
        "#         #self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "#         conv_layer = tf.nn.conv2d(self.input, self.weights1, strides=(1, 1), padding=\"SAME\")\n",
        "#         print(self.input)\n",
        "#         max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2), padding='valid')\n",
        "#         self.layer1 = max_pool_2d(self.input)\n",
        "#         self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
        "\n",
        "#     def backprop(self):\n",
        "#         d_weights2 = np.dot(self.layer1.T, (2 * (self.y - self.output) * sigmoid_derivative(self.output)))\n",
        "#         d_weights1 = np.dot(self.input.T, (np.dot(2 * (self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n",
        "\n",
        "#         self.weights1 += d_weights1 * self.learning_rate\n",
        "#         self.weights2 += d_weights2 * self.learning_rate\n",
        "\n",
        "#     def train(self):\n",
        "#         for i in range(self.epochs):\n",
        "#             self.feedforward()\n",
        "#             self.backprop()\n",
        "\n",
        "#     def mean_squared_error(self):\n",
        "#         return np.mean(np.square(self.y - self.output))\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     X = np.array([[0.1, 0.5, 0.6, 0.3], [0.2, 0.4, 0.2,0.6], [0.4, 0.3, 0.4,0.4], [0.5, 0.2, 0.5,0.3]])\n",
        "#     X = X.reshape(1, 4, 4, 1)\n",
        "#     y = np.array([[0.2], [0.3], [0.4], [0.4]])\n",
        "#     cnn = ConvolutionalNeuralNetwork(X, y)\n",
        "#     cnn.train()\n",
        "#     print(\"Output after training: \\n\", cnn.output)\n",
        "#     print(\"Mean Squared Error: \\n\", cnn.mean_squared_error())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222672a4",
      "metadata": {
        "id": "222672a4"
      },
      "source": [
        "### Q6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f4891d",
      "metadata": {
        "id": "f2f4891d"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "# digit_df = pd.read_csv(\"C:\\SPSoft\\IITJodhpur\\DeepLearning\\MNIST\\mnist_train.csv\")\n",
        "\n",
        "# digit_df.shape\n",
        "\n",
        "# digit_df.head()\n",
        "\n",
        "# digit_df = np.array(digit_df)\n",
        "\n",
        "# m, n = digit_df.shape\n",
        "# np.random.shuffle(digit_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ca24e3",
      "metadata": {
        "id": "23ca24e3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "import win32gui\n",
        "from PIL import ImageGrab, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d373810",
      "metadata": {
        "id": "1d373810",
        "outputId": "75f6d156-7c54-470a-e53a-32a528ba95a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras \n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "479659b8",
      "metadata": {
        "id": "479659b8"
      },
      "source": [
        "### Learning rate = 0.001 , Loss = categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff966b6",
      "metadata": {
        "id": "aff966b6",
        "outputId": "aae619a7-ec71-48a6-e9d5-5f306ed13dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 19s 39ms/step - loss: 2.3054 - accuracy: 0.1082 - val_loss: 2.2881 - val_accuracy: 0.1571\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 2.2894 - accuracy: 0.1255 - val_loss: 2.2710 - val_accuracy: 0.1650\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 2.2744 - accuracy: 0.1457 - val_loss: 2.2545 - val_accuracy: 0.1980\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 2.2604 - accuracy: 0.1646 - val_loss: 2.2378 - val_accuracy: 0.2889\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 2.2462 - accuracy: 0.1892 - val_loss: 2.2203 - val_accuracy: 0.3585\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 2.2293 - accuracy: 0.2085 - val_loss: 2.2007 - val_accuracy: 0.4143\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 2.2124 - accuracy: 0.2267 - val_loss: 2.1790 - val_accuracy: 0.4602\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 2.1957 - accuracy: 0.2412 - val_loss: 2.1550 - val_accuracy: 0.5027\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 2.1754 - accuracy: 0.2563 - val_loss: 2.1282 - val_accuracy: 0.5410\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 2.1533 - accuracy: 0.2722 - val_loss: 2.0987 - val_accuracy: 0.5739\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 2.1273 - accuracy: 0.2885 - val_loss: 2.0658 - val_accuracy: 0.5996\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 2.1021 - accuracy: 0.3012 - val_loss: 2.0305 - val_accuracy: 0.6184\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 2.0750 - accuracy: 0.3120 - val_loss: 1.9923 - val_accuracy: 0.6316\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 20s 44ms/step - loss: 2.0468 - accuracy: 0.3250 - val_loss: 1.9517 - val_accuracy: 0.6405\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 21s 45ms/step - loss: 2.0129 - accuracy: 0.3410 - val_loss: 1.9083 - val_accuracy: 0.6545\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 1.9821 - accuracy: 0.3554 - val_loss: 1.8627 - val_accuracy: 0.6663\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 23s 50ms/step - loss: 1.9479 - accuracy: 0.3639 - val_loss: 1.8159 - val_accuracy: 0.6751\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 1.9150 - accuracy: 0.3769 - val_loss: 1.7678 - val_accuracy: 0.6863\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 1.8800 - accuracy: 0.3886 - val_loss: 1.7188 - val_accuracy: 0.6970\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 1.8456 - accuracy: 0.3970 - val_loss: 1.6700 - val_accuracy: 0.7039\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 21s 46ms/step - loss: 1.8096 - accuracy: 0.4119 - val_loss: 1.6206 - val_accuracy: 0.7110\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 1.7733 - accuracy: 0.4240 - val_loss: 1.5702 - val_accuracy: 0.7199\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 1.7418 - accuracy: 0.4324 - val_loss: 1.5207 - val_accuracy: 0.7265\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 22s 46ms/step - loss: 1.7061 - accuracy: 0.4428 - val_loss: 1.4727 - val_accuracy: 0.7338\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 23s 48ms/step - loss: 1.6696 - accuracy: 0.4555 - val_loss: 1.4251 - val_accuracy: 0.7394\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 22s 48ms/step - loss: 1.6397 - accuracy: 0.4626 - val_loss: 1.3799 - val_accuracy: 0.7465\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 1.6053 - accuracy: 0.4738 - val_loss: 1.3357 - val_accuracy: 0.7530\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 1.5781 - accuracy: 0.4806 - val_loss: 1.2940 - val_accuracy: 0.7605\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 22s 47ms/step - loss: 1.5471 - accuracy: 0.4926 - val_loss: 1.2527 - val_accuracy: 0.7681\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 1.5118 - accuracy: 0.5050 - val_loss: 1.2124 - val_accuracy: 0.7717\n",
            "The model has successfully trained\n",
            "Test loss: 1.2123603820800781\n",
            "Test accuracy: 0.7717000246047974\n",
            "Saving the model as mnist.h5\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(learning_rate=0.001),metrics=['accuracy'])\n",
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26877ab",
      "metadata": {
        "id": "d26877ab"
      },
      "source": [
        "### Learning rate = 0.001 , Loss = binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ebe461",
      "metadata": {
        "id": "d0ebe461",
        "outputId": "1c84d96e-7f53-4901-b199-708f236292aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.3516 - accuracy: 0.2606 - val_loss: 0.1859 - val_accuracy: 0.7580\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.1951 - accuracy: 0.6381 - val_loss: 0.0919 - val_accuracy: 0.8872\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 21s 44ms/step - loss: 0.1373 - accuracy: 0.7723 - val_loss: 0.0635 - val_accuracy: 0.9126\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1056 - accuracy: 0.8397 - val_loss: 0.0463 - val_accuracy: 0.9340\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0844 - accuracy: 0.8800 - val_loss: 0.0366 - val_accuracy: 0.9438\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0692 - accuracy: 0.9051 - val_loss: 0.0292 - val_accuracy: 0.9539\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0583 - accuracy: 0.9222 - val_loss: 0.0248 - val_accuracy: 0.9582\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.0509 - accuracy: 0.9327 - val_loss: 0.0225 - val_accuracy: 0.9618\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0451 - accuracy: 0.9422 - val_loss: 0.0204 - val_accuracy: 0.9668\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0406 - accuracy: 0.9474 - val_loss: 0.0177 - val_accuracy: 0.9716\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 19s 41ms/step - loss: 0.0376 - accuracy: 0.9529 - val_loss: 0.0160 - val_accuracy: 0.9739\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0343 - accuracy: 0.9566 - val_loss: 0.0149 - val_accuracy: 0.9746\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 19s 42ms/step - loss: 0.0326 - accuracy: 0.9590 - val_loss: 0.0146 - val_accuracy: 0.9764\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0306 - accuracy: 0.9622 - val_loss: 0.0131 - val_accuracy: 0.9782\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.0291 - accuracy: 0.9639 - val_loss: 0.0127 - val_accuracy: 0.9794\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 23s 48ms/step - loss: 0.0274 - accuracy: 0.9654 - val_loss: 0.0126 - val_accuracy: 0.9789\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 25s 53ms/step - loss: 0.0263 - accuracy: 0.9676 - val_loss: 0.0121 - val_accuracy: 0.9799\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.0250 - accuracy: 0.9691 - val_loss: 0.0116 - val_accuracy: 0.9810\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 23s 48ms/step - loss: 0.0238 - accuracy: 0.9707 - val_loss: 0.0110 - val_accuracy: 0.9820\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 24s 52ms/step - loss: 0.0231 - accuracy: 0.9716 - val_loss: 0.0103 - val_accuracy: 0.9831\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 26s 55ms/step - loss: 0.0222 - accuracy: 0.9730 - val_loss: 0.0109 - val_accuracy: 0.9820\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 29s 61ms/step - loss: 0.0219 - accuracy: 0.9734 - val_loss: 0.0103 - val_accuracy: 0.9817\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.0210 - accuracy: 0.9748 - val_loss: 0.0097 - val_accuracy: 0.9844\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 37s 79ms/step - loss: 0.0204 - accuracy: 0.9754 - val_loss: 0.0098 - val_accuracy: 0.9837\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 28s 59ms/step - loss: 0.0197 - accuracy: 0.9754 - val_loss: 0.0090 - val_accuracy: 0.9843\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 30s 64ms/step - loss: 0.0193 - accuracy: 0.9762 - val_loss: 0.0093 - val_accuracy: 0.9854\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 28s 59ms/step - loss: 0.0186 - accuracy: 0.9770 - val_loss: 0.0089 - val_accuracy: 0.9856\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 25s 52ms/step - loss: 0.0180 - accuracy: 0.9773 - val_loss: 0.0089 - val_accuracy: 0.9850\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 0.0180 - accuracy: 0.9783 - val_loss: 0.0082 - val_accuracy: 0.9872\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 0.0174 - accuracy: 0.9791 - val_loss: 0.0082 - val_accuracy: 0.9865\n",
            "The model has successfully trained\n",
            "Test loss: 0.008247626014053822\n",
            "Test accuracy: 0.9865000247955322\n",
            "Saving the model as mnist.h5\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.binary_crossentropy   ,optimizer=keras.optimizers.Adadelta(learning_rate=0.1),metrics=['accuracy'])\n",
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf00e22a",
      "metadata": {
        "id": "bf00e22a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}